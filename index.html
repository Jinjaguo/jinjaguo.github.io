<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jinjia Guo</title>

    <meta name="author" content="Jinjia Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jinjia Guo
                </p>
                <p>I am currently pursuing my Master degree of <a href="https://robotics.umich.edu/">Robotics</a> at the <a href="https://umich.edu/">University of Michigan</a> in Ann Arbor. There, I worked in <a href="https://arm.robotics.umich.edu/">ARM Lab</a>  under the guidance of Professor 	
                  <a href="https://berenson.robotics.umich.edu/">Dmitry Berenson</a>. 
                </p>
                <p>
                  Previously, I earned dual Bachelor's degrees in Mechanical Engineering from the <a href="https://researchdirectory.uc.edu/p/dongjg">University of Cincinnati (UC)</a> and <a href="https://english.cqu.edu.cn/">Chongqing University (CQU)</a>. 
                  During my undergraduate studies, I also completed a minor in Robotics at UC.
                  Throughout this period, I engaged in research under the mentorship of <a href="https://researchdirectory.uc.edu/p/dongjg">Professor Janet Jiaxiang Dong</a> and <a href="https://accu.cqu.edu.cn/info/1251/4955.htm">Professor Rui Li</a>. 
                  In addition, in 2022, I collaborated with <a href="https://www.mtu.edu/biomedical/people/graduate/mu.html">Nan Mu</a> and <a href=https://www.mtu.edu/biomedical/people/faculty/jiang/Jingfeng>Professor Jingfeng Jiang</a> at <a href="https://www.mtu.edu/">Michigan Technological University (MTU)</a>.
                <p style="text-align:center">
                  <a href="mailto:jinjaguo@umich.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/jinjiaguo_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=gnYuSmoAAAAJ&hl=en-us">Scholar</a> &nbsp;/&nbsp;
                  <!--<a href="https://bsky.app/profile/jonbarron.bsky.social">Linkedin</a> &nbsp;/&nbsp;  领英没还没弄 --> 
                  <a href="https://github.com/Jinjaguo">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/jinjiaguo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jinjiaguo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research Intersts</h2>
                <p>
                  My primary research interest lies in robotic manipulation, particularly enabling robots to use tools to accomplish practical, everyday tasks. 
                  Motivated by the challenge highlighted by <a href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">Moravec's paradox</a> — that robots struggle with manipulation tasks that are effortless for humans.
                  I focus on developing methods that leverage multi-modal sensory data (such as vision and touch) to build robust and generalizable policies and planning frameworks, empowering robotic hands to perform manipulation tasks more reliably and effectively.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
              <tr>
                <td>
                  <h2>Projects</h2>
                </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    <!--可以把这个项目的背景块高亮
    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
</span>
        </a>
        <br>
				<a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr>
    -->

    <!--视频111111111111111111111111111111111111111111111111111111-->
    <style>
      /* 样式调整，保证图片和视频尺寸一致 */
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1; /* 保持正方形 */
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0; /* 初始隐藏视频 */
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img,
      .one video {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      
      <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id="lp_image">
              <video muted autoplay loop playsinline>
                <source src="images/lp.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <img src="images/LP.png" alt="LP Preview">
          </div>
        </td>
        
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://github.com/Jinjaguo/In-Hand_Screwdriver_Rotation">
            <span class="papertitle">In-Hand Screwdriver Rotation Based on Linear Programming and Diffusion Strategy</span>
          </a>
          <br>
          <a href="https://github.com/Jinjaguo/In-Hand_Screwdriver_Rotation">Project page</a>
          <a href="data/ROB_590_Final_Report.pdf">Report</a>
          <p></p>
          <p>
            We achieve robust in-hand screwdriver manipulation by tightly coupling vision-based point cloud perception with tactile force closure optimization, 
            using diffusion models for trajectory proposals and online LP-based adjustments to maintain stable contact during rotation.
          </p>
        </td>
      </tr>
      
      <script>
      function r2r_start() {
        document.getElementById('lp_image').style.opacity = "1";
      }
      
      function r2r_stop() {
        document.getElementById('lp_image').style.opacity = "0";
      }
      
      // 页面加载时默认隐藏视频
      r2r_stop();
      </script>
    <!--视频1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111-->


    <!--视频2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222-->
    <style>
      /* 样式调整，保证图片和视频尺寸一致 */
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1; /* 保持正方形 */
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0; /* 初始隐藏视频 */
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img,
      .one video {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      
      <tr onmouseout="r2r_stop_2()" onmouseover="r2r_start_2()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id="lmd_image">
              <video muted autoplay loop playsinline>
                <source src="images/lmd.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <img src="images/lmd.png" alt="LP Preview">
          </div>
        </td>
        
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://github.com/Jinjaguo/Learning-Multi-Body-Dynamics">
            <span class="papertitle">Learning Multi Body Dynamicsy</span>
          </a>
          <br>
          <a href="https://github.com/Jinjaguo/Learning-Multi-Body-Dynamics">Project page</a> /
          <a href="data\Learning_Multi_Body_Dynamics.pdf">Report</a>
          <p></p>
          <p>
            We propose a hybrid dynamics modeling approach, SAIN, that combines a physics engine with residual learning. 
            By integrating it with MPPI control, we achieve 100% success rate in manipulating target objects under 40 diverse and randomized physical conditions.
          </p>
        </td>
      </tr>
      
      <script>
      function r2r_start_2() {
        document.getElementById('lmd_image').style.opacity = "1";
      }
      
      function r2r_stop_2() {
        document.getElementById('lmd_image').style.opacity = "0";
      }
      
      // 页面加载时默认隐藏视频
      r2r_stop_2();
      </script>
    <!--视频2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222-->

    <tr>
    <!--图片变化333333333333333333333333333333333333333333333333333333333333333333333333333333333333-->
    <style>
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1;
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0;
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      <tr onmouseout="ever_stop()" onmouseover="ever_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <!-- 第二张图，悬停时显示 -->
            <img id="ever_image" src="images/env2.png" alt="env2" style="position: absolute; top: 0; left: 0;">
            <!-- 第一张图，默认显示 -->
            <img src="images/env1.png" alt="env1">
          </div>
          <script type="text/javascript">
            function ever_start() {
              document.getElementById('ever_image').style.opacity = "1";
            }
            function ever_stop() {
              document.getElementById('ever_image').style.opacity = "0";
            }
            ever_stop();
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://github.com/Jinjaguo/ROB442-EECS465/tree/main/Rob422_HW/Final_Project">
            <span class="papertitle">Search-Based Planning for PR2: ANA* vs A* with Custom Heuristics</span>
          </a>
          <br>
          <a href="https://github.com/Jinjaguo/ROB442-EECS465/tree/main/Rob422_HW/Final_Project">Project page</a> /
          <a href="data/Search_Based_Planning_for_PR2__ANA__vs_A__with_Custom_Heuristics.pdf">Report</a>
          <p></p>
          <p>
            This study compares A* and ANA* algorithms on the PR2 robot, showing that heuristic design critically balances planning efficiency and safety, with ANA* offering greater adaptability in dynamic environments while A* excels in real-time responsiveness.
          </p>
        </td>
      </tr>
      
    <!--图片变化333333333333333333333333333333333333333333333333333333333333333333333333333333-->

    <!--视频4444444444444444444444444444444444444444444444444444444444444444444444444444444444-->
    <style>
      /* 样式调整，保证图片和视频尺寸一致 */
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1; /* 保持正方形 */
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0; /* 初始隐藏视频 */
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img,
      .one video {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      
      <tr onmouseout="r2r_stop_3()" onmouseover="r2r_start_3()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id="bot_image">
              <video muted autoplay loop playsinline>
                <source src="images/bot.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <img src="images/bot.png" alt="LP Preview">
          </div>
        </td>
        
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="data\ROB_550_Report_PM_Group6.pdf">
            <span class="papertitle">Autonomous SLAM and Exploration with MBot</span>
          </a>
          <br>
          <a href="data\ROB_550_Report_PM_Group6.pdf">Report</a>
          <p></p>
          <p>
            In the Botlab, movement control, obstacle detection, maze exploration, and self-localization functionality was developed on the MBot robot, a mobile robot platform. 
            It is designed to explore the fundamentals of robot autonomy by developing MBot with autonomous mapping, localization, and exploration capabilities.
        </td>
      </tr>
      
      <script>
      function r2r_start_3() {
        document.getElementById('bot_image').style.opacity = "1";
      }
      
      function r2r_stop_3() {
        document.getElementById('bot_image').style.opacity = "0";
      }
      
      // 页面加载时默认隐藏视频
      r2r_stop_3();
      </script>
    <!--视频44444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444-->

    <!--视频55555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555-->
    <style>
      /* 样式调整，保证图片和视频尺寸一致 */
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1; /* 保持正方形 */
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0; /* 初始隐藏视频 */
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img,
      .one video {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      
      <tr onmouseout="r2r_stop_4()" onmouseover="r2r_start_4()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id="arm_image">
              <video muted autoplay loop playsinline>
                <source src="images/arm.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <img src="images/arm.jpg" alt="LP Preview">
          </div>
        </td>
        
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://github.com/Jinjaguo/ROB550-Armlab">
            <span class="papertitle">Robust Detecting and Palletizing with Robot Arm</span>
          </a>
          <br>
          <a href="https://github.com/Jinjaguo/ROB550-Armlab">Project page</a> /
          <a href="data\s012-t08-armlab-f24.pdf">Report</a>
          <p></p>
          <p>
            In the Armlab, a 5-DOF robotic arm fully autonomously arranges blocks of different sizes, colors and positions into the desired arrangement. 
            Numerical inverse kinematics is used to determine the appropriate waypoints. An overhead LiDAR Camera is utilized to identify blocks on the board.
          </p>
        </td>
      </tr>
      
      <script>
      function r2r_start_4() {
        document.getElementById('arm_image').style.opacity = "1";
      }
      
      function r2r_stop_4() {
        document.getElementById('arm_image').style.opacity = "0";
      }
      
      // 页面加载时默认隐藏视频
      r2r_stop_4();
      </script>
    <!--视频5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555-->

    <!--视频6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666-->
    <style>
      /* 样式调整，保证图片和视频尺寸一致 */
      .one {
        position: relative;
        width: 100%;
        aspect-ratio: 1/1; /* 保持正方形 */
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0; /* 初始隐藏视频 */
        transition: opacity 0.2s ease-in-out;
      }
      
      .one img,
      .one video {
        display: block;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
      </style>
      
      <tr onmouseout="r2r_stop_5()" onmouseover="r2r_start_5()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id="cap_image">
              <video muted autoplay loop playsinline>
                <source src="images/capture.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
            <img src="images/cap.png" alt="LP Preview">
          </div>
        </td>
        
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="data\GRUOP21">
            <span class="papertitle">Reinforcement Learning for Robotic Capture of Free-Floating Objects in Space</span>
          </a>
          <br>
          <a href="data\GRUOP21">Report</a>
          <p></p>
          <p>
            In the Armlab, a 5-DOF robotic arm fully autonomously arranges blocks of different sizes, colors and positions into the desired arrangement. 
            Numerical inverse kinematics is used to determine the appropriate waypoints. An overhead LiDAR Camera is utilized to identify blocks on the board.
          </p>
        </td>
      </tr>
      
      <script>
      function r2r_start_5() {
        document.getElementById('cap_image').style.opacity = "1";
      }
      
      function r2r_stop_5() {
        document.getElementById('cap_image').style.opacity = "0";
      }
      
      // 页面加载时默认隐藏视频
      r2r_stop_5();
      </script>
    <!--视频6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666-->


    </tbody></table>
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
      <tr>
        <td>
          <h2>Publications</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        
    <!--纯图片-->
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/cla.png" alt="clean-usnob" width="160" height="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9981003">
          <span class="papertitle">An industrial mineral raw material classification method based on image segmentation</span>
        </a>
        <br>
        Xuewen Xiao, <strong>jinjia Guo</strong>, Xin Cao, Xiaohui Zhang, Shuyang Pang</a>
        <br>
        <em>2022 International Conference on Manufacturing, Industrial Automation and Electronics (ICMIAE)
        <p>We developed a Unet++-based image segmentation method for mineral raw material classification, achieving 92.86% precision by accurately identifying and distinguishing particle types at the pixel level.</p>
      </td>
    </tr>
    <!--纯图片-->


    <!--纯图片-->
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <img src="images/Seg.png" alt="clean-usnob" width="160" height="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10394395">
          <span class="papertitle">A Multi-Distance Feature Dissimilarity-Guided Encoder-Decoder Network for Polyp Segmentation</span>
        </a>
        <br>
        Xianchao Zhang, <strong>jinjia Guo</strong>, Nan Mu, <a href=https://www.mtu.edu/biomedical/people/faculty/jiang/Jingfeng>Jingfeng Jiang</a> </a>
        <br>
        <em>2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)
        <p>We propose a multi-distance feature dissimilarity-guided encoder-decoder network, combining MDDM and HLM modules, to achieve more accurate polyp segmentation across diverse datasets by effectively capturing and supervising multi-scale feature differences.</p>
      </td>
    </tr>
    <!--纯图片-->

      <!--纯图片-->
      <tr>
        <td style="padding:16px;width:20%;vertical-align:middle">
          <img src="images/sla.png" alt="clean-usnob" width="160" height="160">
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://www.researchgate.net/publication/375695294_Learning_How_to_Detect_Salient_Objects_in_Nighttime_Scenes">
            <span class="papertitle">Learning How to Detect Salient Objects in Nighttime Sceness</span>
          </a>
          <br>
          Nan Mu, <strong>jinjia Guo</strong>, <a href=https://www.mtu.edu/biomedical/people/faculty/jiang/Jingfeng>Jingfeng Jiang</a> </a>
          <br>
          <em>Journal of Scientific & Industrial Research </em>2023
          <p>We proposed MBNet, a novel network combining high-low feature aggregation and hierarchical supervision for salient object detection in nighttime scenes, achieving superior performance over seven state-of-the-art methods on a newly built low-light dataset.</p>
        </td>
      </tr>
      <!--纯图片-->



          </tbody></table>
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Experiences</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <style>
          /* 可放到你全局的 stylesheet.css 中 */
          .company-logo {
            display: block;
            max-width: 80px;    /* Logo 最大宽度，可根据需要调整 */
            height: auto;
            margin: 0 auto;     /* 水平居中 */
          }
          .work-comp {
            font-weight: bold;
            font-size: 16px;
            margin-bottom: 4px;
          }
          .work-title {
            font-weight:italic;
            font-size: 14px;
          }
          .work-period {
            font-style: italic;
            color: #555;
            font-size: 14px;
          }
        </style>
        
        <table>
          <!-- 一条实习经历 -->
          <tr>
            <!-- 左侧：公司 Logo -->
            <td align="center" style="padding:16px; width:20%; vertical-align:middle;">
              <img class="company-logo" src="images/fitten.png" alt="Company Logo">
            </td>
        
            <!-- 右侧：公司名称 / 职位 / 时间 -->
            <td style="padding:8px; width:80%; vertical-align:middle;">
              <div class="work-comp">Fitten Technology Co., Ltd.</div>
              <div class="work-title">LLM Research Assistant</div>
              <div class="work-period">May/2024 - August/2024</div>
              <p>Applied RAG in JittorLLM, a large language code completion model based on the self-developed framework: Jittor.
                The model reduces latency by 70% and improves accuracy by 20% compared with Copilot.</p>
            </td>
          </tr>
          <!-- 一条实习经历 -->
          <tr>
            <td align="center" style="padding:16px; width:20%; vertical-align:middle;">
              <img class="company-logo" src="images/uc.png" alt="Another Company Logo">
            </td>
            <td style="padding:8px; width:80%; vertical-align:middle;">
              <div class="work-comp">University of Cincinnati</div>
              <div class="work-title">Peer-TA in College of Engineering and Applied Science</div>
              <div class="work-period">August/2023 - April/2024</div>
              <p>Demonstrated strong written and verbal communication skills by providing clear, constructive feedback on assign-
                ments for a cohort of 103 students, ensuring high standards of professionalism and efficiency.</p>
            </td>
          </tr>
          <!-- 一条实习经历 -->
          <tr>
            <td align="center" style="padding:16px; width:20%; vertical-align:middle;">
              <img class="company-logo" src="images/mtu.png" alt="Another Company Logo">
            </td>
            <td style="padding:8px; width:80%; vertical-align:middle;">
              <div class="work-comp">Michigan Technological University </div>
              <div class="work-title">Research Assistant</div>
              <div class="work-period">August/2022 - December/2022, April/2023 - August/2023</div>
              <p>Designed and implemented a new salient object detection network tailored for medical imaging, utilizing multi-scale
                fusion in neural networks to achieve a performance improvement of over 10%.</p>
            </td>
          </tr>
          <!-- 一条实习经历 -->
          <tr>
            <td align="center" style="padding:16px; width:20%; vertical-align:middle;">
              <img class="company-logo" src="images/cisdi.jpg" alt="Another Company Logo">
            </td>
            <td style="padding:8px; width:80%; vertical-align:middle;">
              <div class="work-comp">CISDI INFORMATION Technology Co., Ltd. </div>
              <div class="work-title">Computer Vision Algorithm Assistant</div>
              <div class="work-period">May/2021 - August/2021, January/2022 - April/2022</div>
              <p>Created a dataset for raw-material classification and segmentation and developed a Unet++ algorithm for granularity
                detection on belt machines for Magang (Group) Holding Co., Ltd.</p>
            </td>
          </tr>
        </table>
        

      </tbody></table>
      <table style="width:100%; border:0px; border-spacing:0px; border-collapse:separate; margin-right:auto; margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center; font-size:small;">
              Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
              <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash;
              use the GitHub code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s
              <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
            </p>
          </td>
        </tr>
      </tbody></table>
      
